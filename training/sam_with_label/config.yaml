# lightning.pytorch==2.0.2
# TODO: change monitor to other metrics

subcommand: fit
fit:
  seed_everything: 42

  trainer:
    accelerator: gpu
    strategy: auto
    devices: auto
    num_nodes: 1
    precision: 32-true
    callbacks:
      - class_path: lightning.pytorch.callbacks.model_checkpoint.ModelCheckpoint
        init_args:
          save_top_k: 10
          monitor: val_Dice/mDice
          mode: max
    max_epochs: 40
    overfit_batches: 0
    check_val_every_n_epoch: 1
    log_every_n_steps: 10
    accumulate_grad_batches: 1
    benchmark: null
    use_distributed_sampler: true
    profiler: null
    detect_anomaly: false
    barebones: false
    reload_dataloaders_every_n_epochs: 0
    default_root_dir: experiment_logs/lightning/
    wandb_config:
      name: with label loss
      project: SAM with Labels
      entity: ml-project-2023
      save_dir: experiment_logs
  model:
    model_type: vit_b
    train_image_encoder: false
    train_prompt_encoder: true
    dice_loss_coef: 0.05
    focal_loss_coef: 1
    label_loss_coef: 0.3
    iou_loss_coef: 0.5
    optimizer_type: AdamW
    optimizer_kwargs:
      lr: 0.00001
      weight_decay: 0.1
    dice_loss_params:
      p: 1
      smooth: 1
    focal_loss_params:
      alpha: 0.25
      gamma: 2
    debug: false
  data:
    training_epoch_len: 20000
    validation_epoch_len: 20000
    chunk_size: 64
    batch_size: 32
    delay: 512
    encoder_batch_size: 1
    encoder_device: 'cuda:0'
    cache_path: embedding_cache
    cache_size_limit: 10737418240
    seed: 1166117
    augment_training_data: true
    augment_validation_data: true
  ckpt_path: null
